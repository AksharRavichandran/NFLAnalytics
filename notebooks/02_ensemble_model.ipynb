{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NFL Home Win Ensemble Model\n",
        "\n",
        "This notebook reproduces the ensemble training pipeline (RandomForest + GradientBoosting + LogisticRegression with soft voting) using the processed game-level dataset. It keeps the model in memory (no joblib artifacts).\n",
        "\n",
        "Workflow:\n",
        "- Load or build processed dataset (`data/processed/games_dataset.csv`).\n",
        "- Prepare features (numeric + categorical) and build the preprocessing + ensemble pipeline.\n",
        "- Train on 2019–2021, validate on 2022 (report accuracy, ROC AUC, log loss, Brier).\n",
        "- Optionally refit on 2019–2022 for final in-memory model.\n",
        "\n",
        "Notes:\n",
        "- Ensure data is fetched under `data/raw/` (e.g., run the fetch script or `make fetch`).\n",
        "- If strictly modeling pregame predictions, consider excluding in-game weather (`temp`, `wind`) to avoid leakage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using DATA_DIR= /Users/aksharravichandran/Documents/GitHub/NFLAnalytics/data\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, brier_score_loss\n",
        "\n",
        "DATA_DIR = Path('../data')\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "\n",
        "ID_COLS = ['game_id', 'season', 'week', 'gameday', 'home_team', 'away_team']\n",
        "TARGET = 'home_win'\n",
        "\n",
        "print('Using DATA_DIR=', DATA_DIR.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Processed Dataset (optional)\n",
        "\n",
        "Builds a compact game-level table with engineered rolling features from schedules under `data/raw/schedules/`. If the processed file already exists, you can skip running this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1,599 rows from ../data/processed/games_dataset.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>season</th>\n",
              "      <th>week</th>\n",
              "      <th>gameday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>home_score</th>\n",
              "      <th>away_score</th>\n",
              "      <th>home_win</th>\n",
              "      <th>...</th>\n",
              "      <th>away_roll_pts_for_mean_3</th>\n",
              "      <th>away_roll_pts_for_mean_5</th>\n",
              "      <th>away_roll_pts_against_mean_3</th>\n",
              "      <th>away_roll_pts_against_mean_5</th>\n",
              "      <th>away_st_d_win_rate</th>\n",
              "      <th>away_st_d_margin_mean</th>\n",
              "      <th>away_temp</th>\n",
              "      <th>away_wind</th>\n",
              "      <th>league_pass_rate</th>\n",
              "      <th>league_epa_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019_01_GB_CHI</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-09-05</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>CHI</td>\n",
              "      <td>GB</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.473666</td>\n",
              "      <td>0.027652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019_01_LA_CAR</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-09-08</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>CAR</td>\n",
              "      <td>LA</td>\n",
              "      <td>27.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>87.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.473666</td>\n",
              "      <td>0.027652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019_01_TEN_CLE</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-09-08</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>CLE</td>\n",
              "      <td>TEN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>71.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.473666</td>\n",
              "      <td>0.027652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           game_id  season  week     gameday   weekday home_team away_team  \\\n",
              "0   2019_01_GB_CHI    2019     1  2019-09-05  Thursday       CHI        GB   \n",
              "1   2019_01_LA_CAR    2019     1  2019-09-08    Sunday       CAR        LA   \n",
              "2  2019_01_TEN_CLE    2019     1  2019-09-08    Sunday       CLE       TEN   \n",
              "\n",
              "   home_score  away_score  home_win  ...  away_roll_pts_for_mean_3  \\\n",
              "0         3.0        10.0         0  ...                       NaN   \n",
              "1        27.0        30.0         0  ...                       NaN   \n",
              "2        13.0        43.0         0  ...                       NaN   \n",
              "\n",
              "   away_roll_pts_for_mean_5  away_roll_pts_against_mean_3  \\\n",
              "0                       NaN                           NaN   \n",
              "1                       NaN                           NaN   \n",
              "2                       NaN                           NaN   \n",
              "\n",
              "  away_roll_pts_against_mean_5 away_st_d_win_rate  away_st_d_margin_mean  \\\n",
              "0                          NaN                NaN                    NaN   \n",
              "1                          NaN                NaN                    NaN   \n",
              "2                          NaN                NaN                    NaN   \n",
              "\n",
              "   away_temp  away_wind  league_pass_rate  league_epa_mean  \n",
              "0       65.0       10.0          0.473666         0.027652  \n",
              "1       87.0        3.0          0.473666         0.027652  \n",
              "2       71.0       10.0          0.473666         0.027652  \n",
              "\n",
              "[3 rows x 41 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def _read_csv(path: Path) -> pd.DataFrame:\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "def load_schedules() -> pd.DataFrame:\n",
        "    sched_path = RAW_DIR / 'schedules' / 'schedules_2019_2024.csv'\n",
        "    if not sched_path.exists():\n",
        "        raise FileNotFoundError(f'Missing schedules file at {sched_path}. Run the fetch script first.')\n",
        "    df = _read_csv(sched_path)\n",
        "    if 'gameday' in df.columns:\n",
        "        df['gameday'] = pd.to_datetime(df['gameday'], errors='coerce')\n",
        "    return df\n",
        "\n",
        "def _long_games(sched: pd.DataFrame) -> pd.DataFrame:\n",
        "    base_cols = [\n",
        "        'game_id','season','game_type','week','gameday','weekday',\n",
        "        'spread_line','total_line','div_game','roof','surface','temp','wind',\n",
        "    ]\n",
        "    home = sched.assign(\n",
        "        team=sched['home_team'],\n",
        "        opp=sched['away_team'],\n",
        "        points_for=sched['home_score'],\n",
        "        points_against=sched['away_score'],\n",
        "        is_home=1,\n",
        "        rest=sched.get('home_rest'),\n",
        "        moneyline=sched.get('home_moneyline'),\n",
        "    )[base_cols + ['team','opp','points_for','points_against','is_home','rest','moneyline']]\n",
        "    away = sched.assign(\n",
        "        team=sched['away_team'],\n",
        "        opp=sched['home_team'],\n",
        "        points_for=sched['away_score'],\n",
        "        points_against=sched['home_score'],\n",
        "        is_home=0,\n",
        "        rest=sched.get('away_rest'),\n",
        "        moneyline=sched.get('away_moneyline'),\n",
        "    )[base_cols + ['team','opp','points_for','points_against','is_home','rest','moneyline']]\n",
        "    long_df = pd.concat([home, away], ignore_index=True)\n",
        "    long_df['margin'] = pd.to_numeric(long_df['points_for'], errors='coerce') - pd.to_numeric(long_df['points_against'], errors='coerce')\n",
        "    long_df['win'] = (long_df['margin'] > 0).astype(int)\n",
        "    long_df = long_df.sort_values(['team','season','week']).reset_index(drop=True)\n",
        "    return long_df\n",
        "\n",
        "def _rolling_features(long_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    feats = long_df.copy()\n",
        "    grp = feats.groupby(['team','season'], sort=False)\n",
        "    def add_roll(col: str, name: str, window: int, func: str = 'mean'):\n",
        "        s = grp[col].apply(lambda x: getattr(x.shift(1).rolling(window, min_periods=1), func)())\n",
        "        feats[f'{name}_{window}'] = s.to_numpy()\n",
        "    for w in (3, 5):\n",
        "        add_roll('margin','roll_margin_mean', w, 'mean')\n",
        "        add_roll('win','roll_win_rate', w, 'mean')\n",
        "        add_roll('points_for','roll_pts_for_mean', w, 'mean')\n",
        "        add_roll('points_against','roll_pts_against_mean', w, 'mean')\n",
        "    feats['st_d_win_rate'] = grp['win'].apply(lambda x: x.shift(1).expanding(min_periods=1).mean()).to_numpy()\n",
        "    feats['st_d_margin_mean'] = grp['margin'].apply(lambda x: x.shift(1).expanding(min_periods=1).mean()).to_numpy()\n",
        "    for c in ['rest','moneyline','temp','wind']:\n",
        "        if c in feats.columns:\n",
        "            feats[c] = pd.to_numeric(feats[c], errors='coerce')\n",
        "    return feats\n",
        "\n",
        "def _wide_game_level(sched: pd.DataFrame, team_feats: pd.DataFrame) -> pd.DataFrame:\n",
        "    key_cols = ['game_id','team']\n",
        "    feat_cols = [\n",
        "        'roll_margin_mean_3','roll_margin_mean_5',\n",
        "        'roll_win_rate_3','roll_win_rate_5',\n",
        "        'roll_pts_for_mean_3','roll_pts_for_mean_5',\n",
        "        'roll_pts_against_mean_3','roll_pts_against_mean_5',\n",
        "        'st_d_win_rate','st_d_margin_mean',\n",
        "        'rest','moneyline',\n",
        "    ]\n",
        "    home_merge = team_feats[key_cols + feat_cols + ['temp','wind']].rename(columns={c: f'home_{c}' for c in feat_cols + ['temp','wind']}).rename(columns={'team':'home_team'})\n",
        "    away_merge = team_feats[key_cols + feat_cols + ['temp','wind']].rename(columns={c: f'away_{c}' for c in feat_cols + ['temp','wind']}).rename(columns={'team':'away_team'})\n",
        "    games = sched.merge(home_merge, on=['game_id','home_team'], how='left')\n",
        "    games = games.merge(away_merge, on=['game_id','away_team'], how='left')\n",
        "    games['home_win'] = (pd.to_numeric(games['home_score'], errors='coerce') > pd.to_numeric(games['away_score'], errors='coerce')).astype('Int64')\n",
        "    return games\n",
        "\n",
        "def build_dataset(seasons: Tuple[int, int] = (2019, 2024)) -> pd.DataFrame:\n",
        "    sched = load_schedules()\n",
        "    for c in ['week','season','temp','wind','spread_line','total_line','home_rest','away_rest','home_moneyline','away_moneyline']:\n",
        "        if c in sched.columns:\n",
        "            sched[c] = pd.to_numeric(sched[c], errors='coerce')\n",
        "    s0, s1 = seasons\n",
        "    sched = sched[(sched['season'] >= s0) & (sched['season'] <= s1) & (sched['game_type'].isin(['REG']))].copy()\n",
        "    long_df = _long_games(sched)\n",
        "    team_feats = _rolling_features(long_df)\n",
        "    game_lvl = _wide_game_level(sched, team_feats)\n",
        "    lt_path = DATA_DIR / 'eda' / 'league_trend.csv'\n",
        "    if lt_path.exists():\n",
        "        lt = pd.read_csv(lt_path).rename(columns={'pass_rate':'league_pass_rate','epa_mean':'league_epa_mean'})\n",
        "        lt = lt[['season','week','league_pass_rate','league_epa_mean']]\n",
        "        game_lvl = game_lvl.merge(lt, on=['season','week'], how='left')\n",
        "    keep_cols = [\n",
        "        'game_id','season','week','gameday','weekday',\n",
        "        'home_team','away_team','home_score','away_score','home_win',\n",
        "        'spread_line','total_line','div_game','roof','surface',\n",
        "        'home_rest','away_rest','home_moneyline','away_moneyline',\n",
        "        'home_roll_margin_mean_3','home_roll_margin_mean_5',\n",
        "        'home_roll_win_rate_3','home_roll_win_rate_5',\n",
        "        'home_roll_pts_for_mean_3','home_roll_pts_for_mean_5',\n",
        "        'home_roll_pts_against_mean_3','home_roll_pts_against_mean_5',\n",
        "        'home_st_d_win_rate','home_st_d_margin_mean',\n",
        "        'home_temp','home_wind',\n",
        "        'away_roll_margin_mean_3','away_roll_margin_mean_5',\n",
        "        'away_roll_win_rate_3','away_roll_win_rate_5',\n",
        "        'away_roll_pts_for_mean_3','away_roll_pts_for_mean_5',\n",
        "        'away_roll_pts_against_mean_3','away_roll_pts_against_mean_5',\n",
        "        'away_st_d_win_rate','away_st_d_margin_mean',\n",
        "        'away_temp','away_wind',\n",
        "        'league_pass_rate','league_epa_mean',\n",
        "    ]\n",
        "    keep_cols = [c for c in keep_cols if c in game_lvl.columns]\n",
        "    return game_lvl[keep_cols].copy()\n",
        "\n",
        "processed_path = PROCESSED_DIR / 'games_dataset.csv'\n",
        "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
        "if not processed_path.exists():\n",
        "    df_proc = build_dataset((2019, 2024))\n",
        "    df_proc.to_csv(processed_path, index=False)\n",
        "    print(f'Saved {len(df_proc):,} rows to {processed_path}')\n",
        "else:\n",
        "    df_proc = pd.read_csv(processed_path)\n",
        "    print(f'Loaded {len(df_proc):,} rows from {processed_path}')\n",
        "\n",
        "df_proc.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Model Pipeline\n",
        "\n",
        "Construct numeric/categorical transformers and a soft-voting ensemble. Optionally exclude weather variables to avoid potential leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 4)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Toggle to drop weather features if modeling pregame only\n",
        "EXCLUDE_WEATHER = True\n",
        "\n",
        "exclude = set(ID_COLS + [TARGET, 'home_score', 'away_score'])\n",
        "all_cols = [c for c in df_proc.columns if c not in exclude]\n",
        "\n",
        "if EXCLUDE_WEATHER:\n",
        "    for c in ['home_temp','away_temp','home_wind','away_wind']:\n",
        "        if c in all_cols:\n",
        "            all_cols.remove(c)\n",
        "\n",
        "categorical_features: List[str] = []\n",
        "numeric_features: List[str] = []\n",
        "for c in all_cols:\n",
        "    if df_proc[c].dtype.kind in 'ifu':\n",
        "        numeric_features.append(c)\n",
        "    else:\n",
        "        categorical_features.append(c)\n",
        "# Ensure certain known categoricals are treated as such if present\n",
        "for c in ['weekday','roof','surface','div_game']:\n",
        "    if c in all_cols and c not in categorical_features:\n",
        "        if c in numeric_features:\n",
        "            numeric_features.remove(c)\n",
        "        categorical_features.append(c)\n",
        "\n",
        "def build_pipeline(numeric_features: List[str], categorical_features: List[str]) -> Pipeline:\n",
        "    num_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median'))])\n",
        "    cat_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[('num', num_transformer, numeric_features), ('cat', cat_transformer, categorical_features)]\n",
        "    )\n",
        "    # Base learners with class weights to guard imbalance\n",
        "    rf = RandomForestClassifier(n_estimators=400, max_depth=None, random_state=42, n_jobs=-1, class_weight='balanced')\n",
        "    gb = GradientBoostingClassifier(random_state=42)\n",
        "    lr = LogisticRegression(max_iter=200, solver='lbfgs', class_weight='balanced')\n",
        "    ensemble = VotingClassifier(estimators=[('rf', rf), ('gb', gb), ('lr', lr)], voting='soft', n_jobs=-1)\n",
        "    pipe = Pipeline(steps=[('prep', preprocessor), ('model', ensemble)])\n",
        "    return pipe\n",
        "\n",
        "pipe = build_pipeline(numeric_features, categorical_features)\n",
        "len(numeric_features), len(categorical_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train / Validate\n",
        "\n",
        "Train on 2019–2021 and validate on 2022, then refit on 2019–2022 for the final in-memory model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aksharravichandran/Documents/GitHub/NFLAnalytics/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 200 iteration(s) (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
            "\n",
            "Increase the number of iterations to improve the convergence (max_iter=200).\n",
            "You might also want to scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation (2022) metrics:\n",
            "  accuracy: 0.6236\n",
            "  roc_auc: 0.6859\n",
            "  log_loss: 0.6313\n",
            "  brier: 0.2212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aksharravichandran/Documents/GitHub/NFLAnalytics/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 200 iteration(s) (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
            "\n",
            "Increase the number of iterations to improve the convergence (max_iter=200).\n",
            "You might also want to scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final model trained on seasons 2019–2022 and stored in variable `pipe`.\n"
          ]
        }
      ],
      "source": [
        "def evaluate(y_true: np.ndarray, proba: np.ndarray):\n",
        "    preds = (proba >= 0.5).astype(int)\n",
        "    return {\n",
        "        'accuracy': float(accuracy_score(y_true, preds)),\n",
        "        'roc_auc': float(roc_auc_score(y_true, proba)),\n",
        "        'log_loss': float(log_loss(y_true, np.vstack([1 - proba, proba]).T, labels=[0, 1])),\n",
        "        'brier': float(brier_score_loss(y_true, proba)),\n",
        "    }\n",
        "\n",
        "# Train/val split\n",
        "df_fit = df_proc[df_proc[TARGET].notna()].copy()\n",
        "train_df = df_fit[(df_fit['season'] >= 2019) & (df_fit['season'] <= 2021)].copy()\n",
        "val_df = df_fit[df_fit['season'] == 2022].copy()\n",
        "\n",
        "X_train = train_df[all_cols]\n",
        "y_train = train_df[TARGET].astype(int).values\n",
        "X_val = val_df[all_cols]\n",
        "y_val = val_df[TARGET].astype(int).values\n",
        "\n",
        "# Fit on 2019-2021\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Report 2022 validation metrics\n",
        "if len(X_val) > 0:\n",
        "    val_proba = pipe.predict_proba(X_val)[:, 1]\n",
        "    metrics = evaluate(y_val, val_proba)\n",
        "    print('Validation (2022) metrics:')\n",
        "    for k, v in metrics.items():\n",
        "        print(f'  {k}: {v:.4f}')\n",
        "else:\n",
        "    print('No 2022 validation rows found.')\n",
        "\n",
        "# Refit on 2019-2022 for final in-memory model\n",
        "train_full = df_fit[(df_fit['season'] >= 2019) & (df_fit['season'] <= 2022)].copy()\n",
        "X_full = train_full[all_cols]\n",
        "y_full = train_full[TARGET].astype(int).values\n",
        "pipe.fit(X_full, y_full)\n",
        "print('Final model trained on seasons 2019–2022 and stored in variable `pipe`.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Pipeline and Features\n",
        "\n",
        "Peek at the pipeline structure and expanded feature names (after one-hot encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total transformed features: 44\n",
            "First 25: ['num__spread_line' 'num__total_line' 'num__home_roll_margin_mean_3'\n",
            " 'num__home_roll_margin_mean_5' 'num__home_roll_win_rate_3'\n",
            " 'num__home_roll_win_rate_5' 'num__home_roll_pts_for_mean_3'\n",
            " 'num__home_roll_pts_for_mean_5' 'num__home_roll_pts_against_mean_3'\n",
            " 'num__home_roll_pts_against_mean_5' 'num__home_st_d_win_rate'\n",
            " 'num__home_st_d_margin_mean' 'num__away_roll_margin_mean_3'\n",
            " 'num__away_roll_margin_mean_5' 'num__away_roll_win_rate_3'\n",
            " 'num__away_roll_win_rate_5' 'num__away_roll_pts_for_mean_3'\n",
            " 'num__away_roll_pts_for_mean_5' 'num__away_roll_pts_against_mean_3'\n",
            " 'num__away_roll_pts_against_mean_5' 'num__away_st_d_win_rate'\n",
            " 'num__away_st_d_margin_mean' 'num__league_pass_rate'\n",
            " 'num__league_epa_mean' 'cat__weekday_Friday']\n"
          ]
        }
      ],
      "source": [
        "pipe.named_steps\n",
        "\n",
        "prep = pipe.named_steps['prep']\n",
        "try:\n",
        "    feat_names = prep.get_feature_names_out()\n",
        "    print('Total transformed features:', len(feat_names))\n",
        "    print('First 25:', feat_names[:25])\n",
        "except Exception as e:\n",
        "    print('Feature name introspection not available:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Inference\n",
        "\n",
        "Predict probabilities on a few rows using the in-memory model (`pipe`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.41874589, 0.26284928, 0.51061971, 0.25090728, 0.17958385])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_any = df_proc[df_proc[TARGET].notna()].iloc[:5][all_cols]\n",
        "pipe.predict_proba(X_any)[:, 1]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
